{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d165424-3570-4083-bd39-2abcd8350379",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4493645-0688-4b26-93ef-9e1037cdd8af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storageAccountName = ACCOUNT_NAME\n",
    "sasToken = SAS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "847885d2-cad7-4561-bbb1-1ac3f7918edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mount_adls(blobContainerName):\n",
    "    try:\n",
    "        dbutils.fs.mount(\n",
    "            source = \"wasbs://{}@{}.blob.core.windows.net\".format(blobContainerName, storageAccountName),\n",
    "            mount_point = f\"/mnt/{storageAccountName}/{blobContainerName}\",\n",
    "            #extra_configs = {'fs.azure.account.key.' + storageAccountName + '.blob.core.windows.net': storageAccountAccessKey}\n",
    "            extra_configs = {'fs.azure.sas.' + blobContainerName + '.' + storageAccountName + '.blob.core.windows.net': sasToken}\n",
    "        )\n",
    "        print(\"OK!\")\n",
    "    except Exception as e:\n",
    "        print(\"Falha\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e75ef28-adfe-4282-b3e4-b73858052262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mounts = dbutils.fs.mounts()\n",
    "\n",
    "if not any(mount.mountPoint == f\"/mnt/{ACCOUNT_NAME}/bronze\" for mount in mounts):\n",
    "    mount_adls(\"bronze\")\n",
    "\n",
    "if not any(mount.mountPoint == f\"/mnt/{ACCOUNT_NAME}/silver\" for mount in mounts):\n",
    "    mount_adls(\"silver\")\n",
    "\n",
    "if not any(mount.mountPoint == f\"/mnt/{ACCOUNT_NAME}/gold\" for mount in mounts):\n",
    "    mount_adls(\"gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91e62e77-5e08-4d01-aa5d-2175c87e8da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def bronze():\n",
    "    try:\n",
    "        # Recuperar dados do landing de csv\n",
    "        df_clientes     = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/clientes.csv\")\n",
    "        df_categorias   = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/categorias.csv\")\n",
    "        df_produtos     = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/produtos.csv\")\n",
    "        df_pedidos      = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/pedidos.csv\")\n",
    "        df_itens_pedido = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/itens_pedido.csv\")\n",
    "        df_enderecos    = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/enderecos.csv\")\n",
    "        df_pagamentos   = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/pagamentos.csv\")\n",
    "        df_estoque      = spark.read.option(\"infeschema\", \"true\").option(\"header\", \"true\").csv(f\"/mnt/{storageAccountName}/landing/estoque.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao recuperar dados da landing\")\n",
    "        raise e\n",
    "        return\n",
    "\n",
    "    try: \n",
    "        # Adicionando metadados de data e hora de processamento e nome do arquivo de origem\n",
    "        df_clientes     = df_clientes     .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"clientes.csv\"))\n",
    "        df_categorias   = df_categorias   .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"categorias.csv\"))\n",
    "        df_produtos     = df_produtos     .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"produtos.csv\"))\n",
    "        df_pedidos      = df_pedidos      .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"pedidos.csv\"))\n",
    "        df_itens_pedido = df_itens_pedido .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"itens_pedido.csv\"))\n",
    "        df_enderecos    = df_enderecos    .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"enderecos.csv\"))\n",
    "        df_pagamentos   = df_pagamentos   .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"pagamentos.csv\"))\n",
    "        df_estoque      = df_estoque      .withColumn(\"data_hora_bronze\", lit(datetime.now().timestamp())).withColumn(\"nome_arquivo\", lit(\"estoque.csv\"))\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao adicionar data e nome\")\n",
    "        raise e\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Salvando os dataframes em delta lake (formato de arquivo) no data lake (repositorio cloud)\n",
    "        df_clientes     .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/clientes\")\n",
    "        df_categorias   .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/categorias\")\n",
    "        df_produtos     .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/produtos\")\n",
    "        df_pedidos      .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/pedidos\")\n",
    "        df_itens_pedido .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/itens_pedido\")\n",
    "        df_enderecos    .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/enderecos\")\n",
    "        df_pagamentos   .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/pagamentos\")\n",
    "        df_estoque      .write.format('delta').mode(\"overwrite\").save(f\"/mnt/{storageAccountName}/bronze/estoque\")\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao salvar arquivos no bronze\")\n",
    "        raise e\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b255c7d7-e3ad-4a6b-8c1a-345d67f9d995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
